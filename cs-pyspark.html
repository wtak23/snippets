

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2. pyspark &mdash; Snippets 1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon-penn.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Snippets 1 documentation" href="index.html"/>
        <link rel="up" title="Python-type" href="top-python.html"/>
        <link rel="next" title="3. python-jupyter-notebook" href="cs-py-jupyter-notebook.html"/>
        <link rel="prev" title="1. Python" href="cs-python.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Snippets
          

          
          </a>

          
            
            
              <div class="version">
                1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="top-python.html">Python-type</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cs-python.html">1. Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#random-stack-overflow-questions">1.1. Random Stack-overflow questions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#things-you-can-do-with-a-file-object">1.1.1. Things you can do with a <strong>file</strong> object</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#simplejson">1.1.2. simplejson</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#find-first-occurence-in-a-list">1.1.3. Find first occurence in a list</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#swap-2-items-in-a-list">1.1.4. Swap 2 items in a list</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#check-all-items-in-list-or-dict-is-equal">1.1.5. Check all items in list or dict is equal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#exceptions">1.2. Exceptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#my-most-frequent-lazy-usecase">1.2.1. My most frequent <em>lazy</em> usecase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#top-pandas">1.3. Top-pandas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#pandas-check-if-all-columns-are-equal-in-a-dataframe">1.3.1. Pandas - check if all columns are equal in a DataFrame</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#top-mpl">1.4. top-mpl</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#when-plt-tight-layout-doesn-t-work-as-expected">1.4.1. When plt.tight_layout doesn&#8217;t work as expected</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#append-to-existing-axes-title">1.4.2. Append to existing axes title</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#change-figure-size-of-existing-figure">1.4.3. Change figure size of <em>existing</em> figure</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#plotting-and-saving-figure-on-remotely-on-server-on-sge-submission">1.5. Plotting and saving figure on remotely on server (on sge submission)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#change-i-made-to-my-figure-function">1.5.1. Change i made to my figure function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#check-if-x11-is-enabled-in-python-script">1.5.2. Check if X11 is enabled in python script</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#disk-io">1.6. Disk IO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#write-list-items-to-text">1.6.1. Write list items to text</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#seaborn-and-pandas-plots">1.7. Seaborn and Pandas plots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#mpl-and-sns">1.7.1. mpl and sns?</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#color-palette">1.7.2. Color palette</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#python-commands-from-shell">1.8. Python commands from shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#matplotlib-styling">1.9. Matplotlib styling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#default-color-cycle">1.9.1. Default color cycle</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#colormap-helper">1.9.2. Colormap helper</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#installing-modules">1.10. installing modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#gochtas">1.11. gochtas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#careful-with-array-slicing-may-change-array-values">1.11.1. careful with array slicing! may change array values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#decorator">1.12. decorator</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#plotting-short-snippets">1.13. Plotting - short snippets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#cool-tricks">1.13.1. Cool tricks</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-python.html#plotting-snippets">1.13.2. Plotting Snippets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#id1">1.14. Exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-python.html#clever-tricks">1.15. Clever tricks</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="">2. pyspark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stack-overflows">2.1. Stack overflows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#numpy-array-to-spark-dataframe-trickier-than-i-thought">2.1.1. numpy array to spark dataframe...trickier than i thought...</a></li>
<li class="toctree-l4"><a class="reference internal" href="#adding-new-columns-to-spark-dataframes">2.1.2. Adding new columns to Spark DataFrames</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#handy-snippets">2.2. Handy snippets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#todo-run-this-script">2.2.1. Todo: run this script</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bunch-of-example-scripts">2.2.2. Bunch of example scripts</a></li>
<li class="toctree-l4"><a class="reference internal" href="#use-of-persist-rdd-persistence">2.2.3. Use of persist (RDD persistence)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sql-in-pyspark">2.3. SQL in pyspark</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-sql-dataframes-and-datasets-guide">2.4. Spark SQL, DataFrames and Datasets Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dataframes">2.4.1. DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="#inter-operating-rdd-dataframes">2.4.2. Inter-operating RDD &amp; DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-sources">2.4.3. Data Sources</a></li>
<li class="toctree-l4"><a class="reference internal" href="#saving-to-persistent-tables">2.4.4. Saving to Persistent Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#programming-guide-condensed-summary">2.5. Programming-guide: condensed summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super-basics">2.5.1. Super basics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shared-variables">2.5.2. Shared variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#rdd-operations">2.5.3. RDD operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#random-handy-snippets">2.6. Random handy snippets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#compute-average">2.6.1. compute average</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-py-jupyter-notebook.html">3. python-jupyter-notebook</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-py-jupyter-notebook.html#ipython-notebook-defaults">3.1. Ipython notebook defaults</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-py-jupyter-notebook.html#frequently-used-config">3.1.1. Frequently used config</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-py-jupyter-notebook.html#widgets">3.2. widgets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-py-jupyter-notebook.html#all-widget-types">3.2.1. All widget types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-py-jupyter-notebook.html#current-config">3.3. Current config</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bct.html">4. Brain Connectivity Toolbox</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/bct.algorithms.html">4.1. bct.algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.algorithms.html#functions">4.1.1. Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.algorithms.html#exceptions">4.1.2. Exceptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="generated/bct.utils.html">4.2. bct.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.utils.html#functions">4.2.1. Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.utils.html#exceptions">4.2.2. Exceptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="generated/bct.nbs.html">4.3. bct.nbs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.nbs.html#functions">4.3.1. Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/bct.nbs.html#exceptions">4.3.2. Exceptions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="top-bash.html">Bash-type</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs-bash-commands.html">1. bash-commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#overflows">1.1. Overflows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#more-stuffs-with-ls">1.1.1. More stuffs with ls</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#insightful-sed-example">1.1.2. Insightful sed example</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#remove-colors-from-stdout-harder-than-i-expected">1.1.3. Remove colors from stdout (harder than i expected)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#sigint-and-sigstp">1.1.4. SIGINT and SIGSTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#quoting-with-command-substitution">1.1.5. Quoting with command substitution</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#display-function-names">1.1.6. Display function names</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#get-n-th-line-of-output-used-sed">1.1.7. get n-th line of output (used sed</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#quotes-with-grep">1.1.8. Quotes with grep</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#escaping-single-quotes-a-mess">1.2. Escaping single quotes (a mess...)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#using-rename-command">1.3. Using rename command</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#rename-files-with-suffix-or-prefix">1.3.1. Rename files with suffix or prefix</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#regexp-syntax-with-rename">1.3.2. regexp syntax with rename</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#random-handy-snippets">1.4. Random handy snippets</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#replace-whitespace-with-newline-in-sed">1.5. replace whitespace with newline in sed</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#what-if-multiple-line-is-spanned">1.5.1. What if multiple line is spanned?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#check-running-processes">1.6. check running processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#nohup-vs-disown-vs">1.7. nohup vs disown vs &amp;</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#moving-and-copying">1.8. Moving and copying</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#scp-user">1.8.1. scp user</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#rsync">1.8.2. rsync</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#find">1.9. find</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#note-find-vs-locate">1.9.1. Note: <strong>find</strong> vs <strong>locate</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#command-vs-command-use-latter">1.10. ``command`` vs $(command) (use latter)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#ls-tricks">1.11. ls tricks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#ls-recursively-use-find">1.11.1. ls recursively (use <em>find</em>)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#show-only-symbolic-links-alias-ls-sym">1.11.2. show only symbolic links (<strong>alias ls_sym</strong>)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#print-timestamp">1.12. print timestamp</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#open-image-xdg-open-image-png">1.13. open image ($xdg-open image.png)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#options-with-less-ongoing">1.14. Options with <strong>less</strong> (ongoing)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#history-w-o-line-numbers">1.15. history w/o line-numbers</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#when-xargs-is-needed">1.16. When xargs is needed</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#get-computer-info">1.17. Get computer info</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#mogrify">1.18. mogrify</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#pipe-dreams-xargs-exec-in-find">1.19. Pipe dreams (xargs, -exec in find)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#grep">1.20. Grep</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#grep-recursively">1.20.1. grep recursively</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#to-grep-a-string-pipe-output-of-echo">1.20.2. To grep a string, pipe output of echo</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#d-not-supported-in-linux-grep-as-default-seems-like">1.20.3. <code class="docutils literal"><span class="pre">\d</span></code> not supported in linux grep as default...seems like</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#just-use-double-quotes-for-regex-query">1.20.4. just use double-quotes for regex query</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#selecting-n-th-line-or-word-using-sed-and-awk">1.21. Selecting n-th line or word using sed and awk</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#use-xargs-to-execute-a-command-once-per-line-of-piped-input">1.22. Use xargs to execute a command once per line of piped input</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#run-same-command-multiple-times-for-loop">1.23. Run same command multiple times (for loop)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#clipboard-with-xclip">1.24. clipboard with xclip</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#io-redirection">1.25. IO Redirection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#piping-vs-command-substitution">1.25.1. Piping vs command substitution</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#redirecting-vs-piping">1.25.2. redirecting vs piping</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#output-stdout-and-stderr-to-terminal-and-logfile">1.25.3. Output stdout and stderr to terminal and logfile</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#syntax-reference">1.25.4. syntax reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#bit-on-printf">1.26. Bit on printf</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#examples-from-ss64">1.26.1. Examples from ss64</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#for-loop">1.27. for loop</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#basics">1.27.1. basics</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#multiline-in-terminal">1.27.2. multiline in terminal</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#looping-over-array-elements">1.27.3. Looping over array elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#number-of-elements-in-an-array-using-array">1.27.4. number of elements in an array using <code class="docutils literal"><span class="pre">${#array[&#64;]}</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#avoid-ls-use-globbing-or-find">1.27.5. avoid $(ls)...use globbing or find</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-commands.html#arithmetic-expansion">1.28. arithmetic expansion ((..))</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-commands.html#let-vs">1.28.1. let vs (())?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-bash-scripts.html">2. bash-scripts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#overflow-topics">2.1. Overflow topics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#source-vs-in-bash-synonymous">2.1.1. source vs . in bash (synonymous)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#check-file-existance">2.1.2. Check file existance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#simple-loop-for-python">2.2. Simple loop for python</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#qsub">2.3. qsub</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#my-old-qsub-approach">2.3.1. my old qsub approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#qsub-run">2.3.2. qsub-run</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#place-exit-1-to-end-script">2.4. place exit 1 to end script</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#style-guide-and-conventions">2.5. Style-guide and conventions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#arrays">2.6. arrays</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#expanding-indices">2.6.1. Expanding indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-bash-scripts.html#practical-example">2.6.2. practical example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#control-rsync-recursive-depth">2.7. control rsync recursive depth</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#skip-scp-if-file-exist-tldr-use-rsync">2.8. skip scp if file exist (tldr - use rsync</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#rsync-symlinks">2.9. rsync symlinks</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#appending-concatenating-variables">2.10. Appending/concatenating variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#command-vs-command">2.11. <code class="docutils literal"><span class="pre">command</span></code> vs $(command)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#variable-name-convention">2.12. variable name convention</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#how-to-expand-tilde">2.13. How to expand ~ (tilde)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#create-directory-if-it-doesn-t-exist-06-14-2016-00-17">2.14. Create directory if it doesn&#8217;t exist 06-14-2016 (00:17)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#vs-in-arrays">2.15. [&#64;] vs [*] in arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#id1">2.16. 1&gt;&amp;2</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#if-statements-and-test-conditions">2.17. if statements and test conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#argh-can-t-comment-over-line-breaks">2.18. argh...can&#8217;t comment over line breaks....</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-bash-scripts.html#get-directory-of-running-bash-script">2.19. get directory of running bash script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-qsubber.html">3. qsubber</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-qsubber.html#qsub-helper">3.1. qsub helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-qsubber.html#qsub-helper-old-pre-april-2016">3.2. qsub helper (old, pre April 2016</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-qsubber.html#a-3-step-receipe-for-matlab">3.2.1. A 3 step receipe for matlab</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-qsubber.html#memrec-to-evaluate-appropriate-h-vmem-value">3.2.2. <code class="docutils literal"><span class="pre">memrec</span></code> (to evaluate appropriate <code class="docutils literal"><span class="pre">h_vmem</span></code> value</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-qsubber.html#qstat">3.2.3. <code class="docutils literal"><span class="pre">qstat</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-qsubber.html#usr-bin-time-to-see-multithreaded-or-not">3.2.4. <code class="docutils literal"><span class="pre">/usr/bin/time</span></code> to see multithreaded or not</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-git.html">4. git-snippet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-git.html#random-overflows">4.1. Random Overflows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-git.html#delete-untracked-files">4.1.1. Delete untracked files</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-git.html#change-author-name">4.1.2. change author name</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="top-datascience.html">Data Science</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs-R.html">1. R</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-R.html#snippets-in-rstudio">1.1. Snippets in RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-R.html#current-content-in-r-snippets">1.1.1. Current content in <code class="docutils literal"><span class="pre">r.snippets</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-R.html#todo-break-these-down-to-smaller-pieces">1.2. TODO: break these down to smaller pieces</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-sql.html">2. sql</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-sql.html#style-guidelines-conventions">2.1. Style guidelines, conventions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sql.html#basic-commands-keywords">2.2. Basic commands/keywords</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sql.html#sql-zoo">2.3. sql-zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-sql.html#select-basics">2.3.1. SELECT basics</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sql.html#math-functions">2.3.2. math functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-sql.html#different-rdbms">2.4. different RDBMS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-perl-oneliners.html">3. perl one-liners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#perl-help-refresher-on-command-line-options">3.1. $ perl &#8211;help (refresher on command line options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#file-spacing">3.2. FILE SPACING</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#line-numbering">3.3. LINE NUMBERING</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#calculations">3.4. CALCULATIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#string-creation-and-array-creation">3.5. STRING CREATION AND ARRAY CREATION</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#text-conversion-and-substitution">3.6. TEXT CONVERSION AND SUBSTITUTION</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#selective-printing-and-deleting-of-certain-lines">3.7. SELECTIVE PRINTING AND DELETING OF CERTAIN LINES</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#handy-regular-expressions">3.8. HANDY REGULAR EXPRESSIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#perl-tricks">3.9. PERL TRICKS</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-perl-oneliners.html#perl-one-liners-explained-e-book">3.10. PERL ONE-LINERS EXPLAINED E-BOOK</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-regexp.html">4. regular expressions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-regexp.html#overflows">4.1. Overflows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#use-perl-engine-in-bash">4.1.1. Use Perl engine in bash</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#negate-specific-word">4.1.2. Negate specific word?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-regexp.html#sublimetext">4.2. Sublimetext</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-regexp.html#regular-expression-regexp-for-python">4.3. Regular expression (regexp) for python</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#basic-functions-modules">4.3.1. Basic functions/modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#splitting-strings">4.3.2. Splitting strings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#search-and-replace-with-sub">4.3.3. Search and replace with sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#compilation-flags">4.3.4. Compilation flags</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#greedy-vs-nongreedy">4.3.5. Greedy vs nongreedy</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#improve-readibility-with-re-verbose-flag">4.3.6. Improve readibility with re.Verbose flag</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#named-groups">4.3.7. Named groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#lookahed-assertions">4.3.8. Lookahed assertions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-regexp.html#bunch-of-examples">4.3.9. Bunch of examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-scala.html">5. Scala</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-scala.html#random-overflow-threads">5.1. Random overflow threads</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-scala.html#linear-algebra-in-scala">5.2. Linear algebra in scala?</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-scala.html#scala-lab">5.3. scala-lab?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-computer.html">6. Random notes relating to computer science</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-computer.unix.html">6.1. Unix-related</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-computer.unix.html#terminal-shell-tty-console-the-difference">6.1.1. terminal, shell, tty, console...the difference?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-computer.network.html">6.2. Network notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-computer.network.html#http-messages">6.2.1. HTTP messages</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="top-unix.html">Unix utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs-sed.html">1. sed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-sed.html#references">1.1. References</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#go-to-gnu-manual-for-an-overkill">1.1.1. Go to GNU manual for an overkill :)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#others">1.1.2. Others</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed.html#random-snippets">1.2. Random snippets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#insightful-example">1.2.1. Insightful example</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#fixname-sh">1.2.2. fixname.sh</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed.html#ultra-basics">1.3. Ultra-basics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#basics-print-delete-and-substitution">1.3.1. Basics: print, delete, and substitution</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#deletion-commands">1.3.2. deletion commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#substitution-basics">1.3.3. Substitution basics</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-sed.html#the-e-f-options">1.3.4. the -e, -f options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed.html#sed-help">1.4. sed &#8211;help</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed.html#output-from-man-page">1.5. output from man page</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-sed-oneliners.html">2. sed oneliners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#sed-help">2.1. sed &#8211;help</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#typical-use">2.2. Typical use</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#file-spacing">2.3. FILE SPACING:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#numbering">2.4. NUMBERING:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#text-conversion-and-substitution">2.5. TEXT CONVERSION AND SUBSTITUTION:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#selective-printing-of-certain-lines">2.6. SELECTIVE PRINTING OF CERTAIN LINES:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#selective-deletion-of-certain-lines">2.7. SELECTIVE DELETION OF CERTAIN LINES:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#special-applications">2.8. SPECIAL APPLICATIONS:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-sed-oneliners.html#misc">2.9. Misc</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-awk.html">3. awk</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-awk.html#note-do-i-really-need-awk">3.1. note: do I really need awk?</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk.html#my-use-case-for-awk-for-files-containing-columns-fields">3.2. My use-case for awk (for files containing columns/fields)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk.html#random-snippets">3.3. Random snippets</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk.html#awk-one-liners">3.4. awk (one-liners)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-awk.html#great-examples-here">3.4.1. Great examples here!</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk.html#awk-help">3.5. awk &#8211;help</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-awk-oneliners.html">4. awk-oneliners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#file-spacing">4.1. File spacing</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#numbering-and-calculations">4.2. NUMBERING AND CALCULATIONS:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#string-creation">4.3. STRING CREATION:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#array-creation">4.4. ARRAY CREATION:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#text-conversion-and-substitution">4.5. TEXT CONVERSION AND SUBSTITUTION:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#selective-printing-of-certain-lines">4.6. SELECTIVE PRINTING OF CERTAIN LINES:</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-awk-oneliners.html#selective-deletion-of-certain-lines">4.7. SELECTIVE DELETION OF CERTAIN LINES:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="top-rst.html">Sphinx/RST-notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs-rst.html">1. rst</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#best-lookups">1.1. Best lookups</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#important-external-directives">1.2. Important external directives</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#random-overflows">1.3. Random overflows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#get-colors">1.3.1. Get colors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#add-links-without-labels">1.3.2. Add links without labels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#link-is-kinda-confusing">1.4. Link is kinda confusing...</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#hmmm">1.4.1. hmmm</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#ah-finally-what-i-wanted">1.4.2. Ah, finally what i wanted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#csv-demo">1.5. csv-demo</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.html#lookups-old-may-remove-this-section">1.6. Lookups (old, may remove this section)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#references-for-rst-in-general-non-sphinx">1.6.1. References for rst in general (non-sphinx)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.html#autodoc-related">1.6.2. Autodoc related</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-rst.directive-test.html">2. Test runs on RST directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.directive-test.html#admonitions">2.1. Admonitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.directive-test.html#epigraph">2.2. Epigraph</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-rst.math_part1.html">3. Latex mathematics on sphinx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#symbols">3.1. Symbols</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#greek-letters">3.2. Greek letters</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#operators">3.3. Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#fractions-and-binomials">3.4. Fractions and Binomials</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#square-roots">3.5. Square roots</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#sum-and-integrals">3.6. Sum and integrals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#big-commands">3.6.1. <strong>BIG</strong> commands</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#brackets-braces-and-delimiters">3.7. Brackets, braces and delimiters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#automatic-sizing">3.7.1. Automatic sizing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#manual-sizing">3.7.2. Manual sizing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#typesetting-intervals">3.7.3. Typesetting intervals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#matrices-and-array">3.8. Matrices and array</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#more-fancy-ones">3.8.1. More fancy ones</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#adding-text-to-equations">3.9. Adding text to equations</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#formatting-mathematics-symbols">3.10. Formatting mathematics symbols</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#accents">3.10.1. Accents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#color-works">3.11. Color (works!)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#plus-and-minus">3.12. Plus and minus</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#controlling-horizontal-spacing">3.13. Controlling horizontal spacing</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#dots">3.14. Dots</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst.math_part1.html#list-of-mathematical-symbols">3.15. List of Mathematical Symbols</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#other-symbols">3.15.1. Other symbols</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst.math_part1.html#trigonemtrics">3.15.2. Trigonemtrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs_rst.math_part2.html">4. Advanced Latex Mathematics on Sphinx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#some-self-notes-i-created">4.1. Some self-notes I created</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs_rst.math_part2.html#bold-for-lower-case-greek">4.1.1. bold for lower-case greek</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs_rst.math_part2.html#defining-own-function">4.1.2. Defining own function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#equations">4.2. Equations</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#vertical-alignment">4.3. Vertical alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#more-aligns">4.4. More aligns</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#braces-spanning-multiple-lines">4.5. Braces spanning multiple lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#aligning-braces-for-piecewise-functions">4.6. Aligning braces for piecewise functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#the-cases-environment">4.7. The <strong>cases</strong> environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#more-exotic-examples">4.8. More exotic examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#boxed-equations">4.9. Boxed equations</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#custom-operator-ah-argmax">4.10. Custom operator (ah, argmax!)</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#advanced-formatting">4.11. Advanced formatting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs_rst.math_part2.html#limits">4.11.1. Limits</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs_rst.math_part2.html#subscripts-and-supterscripts">4.11.2. Subscripts and supterscripts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs_rst.math_part2.html#changing-font-size">4.12. Changing font size</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs-rst.ipython.html">5. Demo runs of ipython sphinx extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs-rst-old.html">6. rst cheatsheet (old)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs-rst-old.html#directives-i-found-useful-or-runs-on-github">6.1. DIRECTIVES I FOUND USEFUL OR RUNS ON GITHUB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#image">6.1.1. .. image::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#code-use-with-number-lines-option">6.1.2. .. code:: (use with <code class="docutils literal"><span class="pre">:number-lines:</span></code> option)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#table">6.1.3. .. table::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#csv-table">6.1.4. .. csv-table::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#contents">6.1.5. .. contents::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#sectnum-works-but-warning-seem-to-screw-up-the-toc-link">6.1.6. .. sectnum:: ...works....but <strong>WARNING!</strong> - seem to screw up the TOC link</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#header-and-footer">6.1.7. .. header:: (and .. footer::)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#sadly-math-doesn-t-render-on-github-works-on-bitbucket">6.1.8. Sadly <code class="docutils literal"><span class="pre">..</span> <span class="pre">math::</span></code> doesn&#8217;t render on github (works on bitbucket)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#replace">6.1.9. .. replace::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#unicode">6.1.10. .. unicode::</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#date">6.1.11. ..date::</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst-old.html#list-of-gotcha-s-to-watch-out-for-at-least-the-ones-i-suffered-from">6.2. List of <strong>GOTCHA&#8217;s</strong> to watch out for (at least the ones I suffered from...)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#gotcha-s-with-nested-list-items">6.2.1. Gotcha&#8217;s with nested list items</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#id1">6.2.2. Sadly <code class="docutils literal"><span class="pre">..</span> <span class="pre">math::</span></code> doesn&#8217;t render on github (works on bitbucket)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#gotcha-s-with-contents">6.2.3. GOTCHA&#8217;s with <code class="docutils literal"><span class="pre">..</span> <span class="pre">contents::</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#h1-h2-problems">6.2.4. <code class="docutils literal"><span class="pre">h1</span></code> <code class="docutils literal"><span class="pre">h2</span></code> ... problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#including-styles-on-header-names-will-break-the-toc-link-on-github-unconfirmed">6.2.5. Including styles on HEADER-NAMES will break the TOC link on github (unconfirmed)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#directives-that-just-doesnt-work-on-github-or-sublime-text">6.2.6. Directives that just doesnt work on github or Sublime Text</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#some-special-characters-that-may-be-a-head-ache-to-print">6.2.7. Some special characters that may be a head-ache to print</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs-rst-old.html#roles-in-rst">6.3. <code class="docutils literal"><span class="pre">roles</span></code> in RST</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#list-of-equivalent-roles-ultra-incomplete">6.3.1. List of equivalent <code class="docutils literal"><span class="pre">roles</span></code> (ultra-incomplete)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs-rst-old.html#some-interesting-looking-roles">6.3.2. Some interesting looking <code class="docutils literal"><span class="pre">roles</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="configs/top-configs.html">configs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="configs/configs.python.html">1. configs.python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configs/configs.python.html#ipython">1.1. ipython</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configs/configs.gitconfig.html">2. configs.gitconfig</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configs/configs.gitconfig.html#sbia-office-computer">2.1. SBIA office computer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configs/configs.bashrc.html">3. configs.bashrc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configs/configs.bashrc.html#my-current-bashrc-file-in-my-office">3.1. My current .bashrc file in my office</a></li>
<li class="toctree-l3"><a class="reference internal" href="configs/configs.bashrc.html#my-current-bashrc-file-in-cygwin">3.2. My current .bashrc file in cygwin</a></li>
<li class="toctree-l3"><a class="reference internal" href="configs/configs.bashrc.html#my-current-bash-aliases-file-in-cygwin">3.3. My current .bash_aliases file in cygwin</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configs/configs.sublime.html">4. configs.sublime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configs/sublime/sublime.sbia.setup.html">4.1. SBIA Workstation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.sbia.setup.html#file-tree">4.1.1. File-tree</a></li>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.sbia.setup.html#symbolic-links-created">4.1.2. Symbolic links created</a></li>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.sbia.setup.html#preferences-sublime-settings-content">4.1.3. Preferences.sublime-settings Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.sbia.setup.html#default-linux-sublime-keymap-content">4.1.4. Default (Linux).sublime-keymap Content</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="configs/sublime/sublime.windows.setup.html">4.2. Windows setup (todo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="configs/sublime/sublime.references.html">4.3. Sublime-Text References</a><ul>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.references.html#scope-info-for-snippets-and-build-system">4.3.1. Scope info (for snippets and build system)</a></li>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.references.html#build-system-info">4.3.2. Build system info</a></li>
<li class="toctree-l4"><a class="reference internal" href="configs/sublime/sublime.references.html#when-sublime-keeps-crashing-at-startup">4.3.3. When sublime keeps crashing at startup...</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Snippets</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="top-python.html">Python-type</a> &raquo;</li>
        
      <li>2. pyspark</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/cs-pyspark.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyspark">
<h1>2. pyspark<a class="headerlink" href="#pyspark" title="Permalink to this headline"></a></h1>
<ul class="simple">
<li><a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">http://spark.apache.org/docs/latest/programming-guide.html</a></li>
<li><a class="reference external" href="http://spark.apache.org/docs/latest/submitting-applications.html">http://spark.apache.org/docs/latest/submitting-applications.html</a></li>
<li><a class="reference external" href="https://wtak23.github.io/pyspark_doc/index.html">https://wtak23.github.io/pyspark_doc/index.html</a></li>
<li><a class="reference external" href="https://databricks.com/resources/type/example-notebooks">https://databricks.com/resources/type/example-notebooks</a></li>
</ul>
<p>Good tuorials</p>
<ul class="simple">
<li><a class="reference external" href="https://s3.amazonaws.com/sparksummit-share/ml-ams-1.0.1/index.html">https://s3.amazonaws.com/sparksummit-share/ml-ams-1.0.1/index.html</a></li>
<li><a class="reference external" href="https://spark-summit.org/2016/">Spark 2016 summit</a></li>
</ul>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title first"><cite>Table of contents</cite></p>
<ul class="simple">
<li><a class="reference internal" href="#stack-overflows" id="id1">Stack overflows</a><ul>
<li><a class="reference internal" href="#numpy-array-to-spark-dataframe-trickier-than-i-thought" id="id2">numpy array to spark dataframe...trickier than i thought...</a></li>
<li><a class="reference internal" href="#adding-new-columns-to-spark-dataframes" id="id3">Adding new columns to Spark DataFrames</a></li>
</ul>
</li>
<li><a class="reference internal" href="#handy-snippets" id="id4">Handy snippets</a><ul>
<li><a class="reference internal" href="#todo-run-this-script" id="id5">Todo: run this script</a></li>
<li><a class="reference internal" href="#bunch-of-example-scripts" id="id6">Bunch of example scripts</a></li>
<li><a class="reference internal" href="#use-of-persist-rdd-persistence" id="id7">Use of persist (RDD persistence)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sql-in-pyspark" id="id8">SQL in pyspark</a></li>
<li><a class="reference internal" href="#spark-sql-dataframes-and-datasets-guide" id="id9">Spark SQL, DataFrames and Datasets Guide</a><ul>
<li><a class="reference internal" href="#dataframes" id="id10">DataFrames</a></li>
<li><a class="reference internal" href="#inter-operating-rdd-dataframes" id="id11">Inter-operating RDD &amp; DataFrames</a></li>
<li><a class="reference internal" href="#data-sources" id="id12">Data Sources</a></li>
<li><a class="reference internal" href="#saving-to-persistent-tables" id="id13">Saving to Persistent Tables</a></li>
</ul>
</li>
<li><a class="reference internal" href="#programming-guide-condensed-summary" id="id14">Programming-guide: condensed summary</a><ul>
<li><a class="reference internal" href="#super-basics" id="id15">Super basics</a></li>
<li><a class="reference internal" href="#shared-variables" id="id16">Shared variables</a></li>
<li><a class="reference internal" href="#rdd-operations" id="id17">RDD operations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#random-handy-snippets" id="id18">Random handy snippets</a><ul>
<li><a class="reference internal" href="#compute-average" id="id19">compute average</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="stack-overflows">
<h2><a class="toc-backref" href="#id1">2.1. Stack overflows</a><a class="headerlink" href="#stack-overflows" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><a class="reference external" href="http://stackoverflow.com/questions/30787635/takeordered-descending-pyspark">http://stackoverflow.com/questions/30787635/takeordered-descending-pyspark</a></li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">RDD</span><span class="o">.</span><span class="n">takeOrdered</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># sort by keys</span>
<span class="n">RDD</span><span class="o">.</span><span class="n">takeOrdered</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># sort by keys (descending)</span>
<span class="n">RDD</span><span class="o">.</span><span class="n">takeOrdered</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># sort by values</span>
<span class="n">RDD</span><span class="o">.</span><span class="n">takeOrdered</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># sort by values (descending)</span>
</pre></div>
</div>
<div class="section" id="numpy-array-to-spark-dataframe-trickier-than-i-thought">
<h3><a class="toc-backref" href="#id2">2.1.1. numpy array to spark dataframe...trickier than i thought...</a><a class="headerlink" href="#numpy-array-to-spark-dataframe-trickier-than-i-thought" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><a class="reference external" href="http://stackoverflow.com/questions/32742004/create-spark-dataframe-can-not-infer-schema-for-type-type-float">http://stackoverflow.com/questions/32742004/create-spark-dataframe-can-not-infer-schema-for-type-type-float</a></li>
</ul>
<p>This bit me in the ass during edX...</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">myFloatRdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">])</span>
<span class="c1">#df = myFloatRdd.toDF() #&lt;- won&#39;t work1 raises a TypeError</span>
<span class="n">myFloatRdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">))</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># &lt;- need to give in tuple format...</span>
<span class="c1">#+---+</span>
<span class="c1">#| _1|</span>
<span class="c1">#+---+</span>
<span class="c1">#|1.0|</span>
<span class="c1">#|2.0|</span>
<span class="c1">#|3.0|</span>
<span class="c1">#+---+</span>

<span class="c1"># or even better...</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>
<span class="n">row</span> <span class="o">=</span> <span class="n">Row</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span> <span class="c1"># Or some other column name</span>
<span class="n">myFloatRdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">#+---+</span>
<span class="c1">#|val|</span>
<span class="c1">#+---+</span>
<span class="c1">#|1.0|</span>
<span class="c1">#|2.0|</span>
<span class="c1">#|3.0|</span>
<span class="c1">#+---+</span>
</pre></div>
</div>
</div>
<div class="section" id="adding-new-columns-to-spark-dataframes">
<h3><a class="toc-backref" href="#id3">2.1.2. Adding new columns to Spark DataFrames</a><a class="headerlink" href="#adding-new-columns-to-spark-dataframes" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><a class="reference external" href="http://stackoverflow.com/questions/33681487/how-do-i-add-a-new-column-to-spark-data-frame-pyspark">http://stackoverflow.com/questions/33681487/how-do-i-add-a-new-column-to-spark-data-frame-pyspark</a></li>
</ul>
<p>You cannot add an arbitrary column to a <code class="docutils literal"><span class="pre">DataFrame</span></code> in Spark.</p>
<p>4 approaches:</p>
<ol class="arabic simple">
<li>use <code class="docutils literal"><span class="pre">pyspark.sql.functions.lit</span></code>, <strong>literals</strong></li>
</ol>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">lit</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mf">23.0</span><span class="p">)],</span> <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">))</span>
<span class="n">df_with_x4</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">df_with_x4</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## +---+---+-----+---+</span>
<span class="c1">## | x1| x2|   x3| x4|</span>
<span class="c1">## +---+---+-----+---+</span>
<span class="c1">## |  1|  a| 23.0|  0|</span>
<span class="c1">## |  3|  B|-23.0|  0|</span>
<span class="c1">## +---+---+-----+---+</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li>transorm an existing column</li>
</ol>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">exp</span>
<span class="n">df_with_x5</span> <span class="o">=</span> <span class="n">df_with_x4</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;x5&quot;</span><span class="p">,</span> <span class="n">exp</span><span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">))</span>
<span class="n">df_with_x5</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## +---+---+-----+---+--------------------+</span>
<span class="c1">## | x1| x2|   x3| x4|                  x5|</span>
<span class="c1">## +---+---+-----+---+--------------------+</span>
<span class="c1">## |  1|  a| 23.0|  0| 9.744803446248903E9|</span>
<span class="c1">## |  3|  B|-23.0|  0|1.026187963170189...|</span>
<span class="c1">## +---+---+-----+---+--------------------+</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>use <code class="docutils literal"><span class="pre">.join</span></code></li>
</ol>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">lookup</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;bar&quot;</span><span class="p">)],</span> <span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">))</span>
<span class="n">df_with_x6</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_with_x5</span>
    <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lookup</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">),</span> <span class="s2">&quot;leftouter&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;v&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">))</span>
<span class="c1">## +---+---+-----+---+--------------------+----+</span>
<span class="c1">## | x1| x2|   x3| x4|                  x5|  x6|</span>
<span class="c1">## +---+---+-----+---+--------------------+----+</span>
<span class="c1">## |  1|  a| 23.0|  0| 9.744803446248903E9| foo|</span>
<span class="c1">## |  3|  B|-23.0|  0|1.026187963170189...|null|</span>
<span class="c1">## +---+---+-----+---+--------------------+----+</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>use udf/function</li>
</ol>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">rand</span>
<span class="n">df_with_x7</span> <span class="o">=</span> <span class="n">df_with_x6</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;x7&quot;</span><span class="p">,</span> <span class="n">rand</span><span class="p">())</span>
<span class="n">df_with_x7</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## +---+---+-----+---+--------------------+----+-------------------+</span>
<span class="c1">## | x1| x2|   x3| x4|                  x5|  x6|                 x7|</span>
<span class="c1">## +---+---+-----+---+--------------------+----+-------------------+</span>
<span class="c1">## |  1|  a| 23.0|  0| 9.744803446248903E9| foo|0.41930610446846617|</span>
<span class="c1">## |  3|  B|-23.0|  0|1.026187963170189...|null|0.37801881545497873|</span>
<span class="c1">## +---+---+-----+---+--------------------+----+-------------------+</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="handy-snippets">
<h2><a class="toc-backref" href="#id4">2.2. Handy snippets</a><a class="headerlink" href="#handy-snippets" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/quick-start.html">https://spark.apache.org/docs/latest/quick-start.html</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># this creates an RDD object</span>
<span class="n">textFile</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;README.md&quot;</span><span class="p">)</span>

<span class="n">textFile</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># Number of items in this RDD</span>
<span class="mi">126</span>

<span class="n">textFile</span><span class="o">.</span><span class="n">first</span><span class="p">()</span> <span class="c1"># First item in this RDD</span>
<span class="s1">u&#39;# Apache Spark&#39;</span>

<span class="n">linesWithSpark</span> <span class="o">=</span> <span class="n">textFile</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="s2">&quot;Spark&quot;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">)</span>
<span class="n">textFile</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="s2">&quot;Spark&quot;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># How many lines contain &quot;Spark&quot;?</span>
<span class="mi">15</span>

<span class="c1"># find the line with the most words</span>
<span class="n">textFile</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="k">if</span> <span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">)</span> <span class="k">else</span> <span class="n">b</span><span class="p">)</span>
<span class="mi">15</span>

<span class="c1"># we can also pass a top-level python function (instead of anonymous functions like above)</span>
<span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">b</span>
<span class="n">textFile</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="nb">max</span><span class="p">)</span>

<span class="c1">#======================================================================#</span>
<span class="c1"># One common data flow pattern is MapReduce, as popularized by Hadoop.</span>
<span class="c1"># Spark can implement MapReduce flows easily:</span>
<span class="c1">#======================================================================#</span>
<span class="c1"># compute the per-word counts in the file as an RDD of (string, int) pairs</span>
<span class="n">wordCounts</span> <span class="o">=</span> <span class="p">(</span><span class="n">textFile</span>
                <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">))</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="p">[(</span><span class="s1">u&#39;and&#39;</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;A&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;webpage&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;README&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;Note&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;&quot;local&quot;&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">u&#39;variable&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span>

<span class="c1"># caching can help when you query small &quot;hot&quot; dataset or running iterative</span>
<span class="c1"># alg. like page-rank</span>
<span class="n">linesWithSpark</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">linesWithSpark</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">19</span>
<span class="n">linesWithSpark</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">19</span>
</pre></div>
</div>
<div class="section" id="todo-run-this-script">
<h3><a class="toc-backref" href="#id5">2.2.1. Todo: run this script</a><a class="headerlink" href="#todo-run-this-script" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/quick-start.html#self-contained-applications">https://spark.apache.org/docs/latest/quick-start.html#self-contained-applications</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;SimpleApp.py&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>

<span class="n">logFile</span> <span class="o">=</span> <span class="s2">&quot;YOUR_SPARK_HOME/README.md&quot;</span>  <span class="c1"># Should be some file on your system</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;Simple App&quot;</span><span class="p">)</span>
<span class="n">logData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="n">logFile</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">numAs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">numBs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Lines with a: </span><span class="si">%i</span><span class="s2">, lines with b: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">numAs</span><span class="p">,</span> <span class="n">numBs</span><span class="p">))</span>
</pre></div>
</div>
<p>Submit this script using <code class="docutils literal"><span class="pre">bin/spark-submit</span></code> script</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="c1"># Use spark-submit to run your application</span>
$ YOUR_SPARK_HOME/bin/spark-submit --master local<span class="o">[</span>4<span class="o">]</span> SimpleApp.py
...
Lines with a: 46, Lines with b: 23
</pre></div>
</div>
</div>
<div class="section" id="bunch-of-example-scripts">
<h3><a class="toc-backref" href="#id6">2.2.2. Bunch of example scripts</a><a class="headerlink" href="#bunch-of-example-scripts" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://github.com/apache/spark/tree/master/examples/src/main/python">https://github.com/apache/spark/tree/master/examples/src/main/python</a></p>
</div>
<div class="section" id="use-of-persist-rdd-persistence">
<h3><a class="toc-backref" href="#id7">2.2.3. Use of persist (RDD persistence)</a><a class="headerlink" href="#use-of-persist-rdd-persistence" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><a class="reference external" href="https://spark.apache.org/docs/latest/programming-guide.html#basics">https://spark.apache.org/docs/latest/programming-guide.html#basics</a></li>
<li><a class="reference external" href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence">https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence</a></li>
</ul>
<p>One of the most important capabilities in Spark is persisting (or caching) a
dataset in memory across operations. When you persist an RDD, each node stores
any partitions of it that it computes in memory and reuses them in other
actions on that dataset (or datasets derived from it). This allows future
actions to be much faster (often by more than 10x). <strong>Caching is a key tool for
iterative algorithms and fast interactive use</strong>.</p>
<p>You can mark an RDD to be persisted using the <code class="docutils literal"><span class="pre">persist()</span></code> or <code class="docutils literal"><span class="pre">cache()</span></code> methods on it.</p>
<ul class="simple">
<li>The first time it is computed in an action, it will be kept in memory on the nodes.</li>
<li>Spark&#8217;s cache is <strong>fault-tolerant</strong>  if any partition of an RDD is lost,
it will automatically be recomputed using the transformations that
originally created it.</li>
</ul>
<p>In addition, each persisted RDD can be stored using a different <strong>storage level</strong>,
allowing you, for example, to persist the dataset on disk, persist it in
memory but as serialized Java objects (to save space), replicate it across nodes.</p>
<ul class="simple">
<li>These levels are set by passing a <code class="docutils literal"><span class="pre">StorageLevel</span></code> object (Scala, Java, Python) to <code class="docutils literal"><span class="pre">persist()</span></code>.</li>
<li>The <code class="docutils literal"><span class="pre">cache()</span></code> method is a shorthand for using the default storage level,
which is <code class="docutils literal"><span class="pre">StorageLevel.MEMORY_ONLY</span></code> (store deserialized objects in memory).</li>
<li>The full set of storage levels is
(<a class="reference external" href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence">link</a>)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data.txt&quot;</span><span class="p">)</span>
<span class="n">lineLengths</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
<span class="n">totalLength</span> <span class="o">=</span> <span class="n">lineLengths</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># if you want to use lineLengths again later, do this before reduce</span>
<span class="c1"># (saves the data in memory)</span>
<span class="n">lineLengths</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="sql-in-pyspark">
<h2><a class="toc-backref" href="#id8">2.3. SQL in pyspark</a><a class="headerlink" href="#sql-in-pyspark" title="Permalink to this headline"></a></h2>
<p>Using Spark SQL within a Python Notebook</p>
<p>You can use execute SQL commands within a python notebook by invoking %sql or using <code class="docutils literal"><span class="pre">sqlContext.sql(...)</span></code>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">sql</span> <span class="n">show</span> <span class="n">functions</span>
</pre></div>
</div>
</div>
<div class="section" id="spark-sql-dataframes-and-datasets-guide">
<h2><a class="toc-backref" href="#id9">2.4. Spark SQL, DataFrames and Datasets Guide</a><a class="headerlink" href="#spark-sql-dataframes-and-datasets-guide" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</a></p>
<div class="section" id="dataframes">
<h3><a class="toc-backref" href="#id10">2.4.1. DataFrames</a><a class="headerlink" href="#dataframes" title="Permalink to this headline"></a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1">#======================================================================#</span>
<span class="c1"># create a basic SparkSession using SparkSession.builder</span>
<span class="c1">#======================================================================#</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># SparkSession in Spark 2.0 provides builtin support for Hive features</span>
<span class="c1"># including the ability to write queries using HiveQL</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span>\
    <span class="o">.</span><span class="n">builder</span>\
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;PythonSQL&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.some.config.option&quot;</span><span class="p">,</span> <span class="s2">&quot;some-value&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># spark is an existing SparkSession</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">)</span>

<span class="c1"># Displays the content of the DataFrame to stdout</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## age  name</span>
<span class="c1">## null Michael</span>
<span class="c1">## 30   Andy</span>
<span class="c1">## 19   Justin</span>

<span class="c1"># Print the schema in a tree format</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1">## root</span>
<span class="c1">## |-- age: long (nullable = true)</span>
<span class="c1">## |-- name: string (nullable = true)</span>

<span class="c1"># Select only the &quot;name&quot; column</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Select everybody, but increment the age by 1</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## name    (age + 1)</span>
<span class="c1">## Michael null</span>
<span class="c1">## Andy    31</span>
<span class="c1">## Justin  20</span>

<span class="c1"># Select people older than 21</span>
<span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">21</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">## age name</span>
<span class="c1">## 30  Andy</span>

<span class="c1">#======================================================================#</span>
<span class="c1"># run SQL Queries programatically</span>
<span class="c1">#======================================================================#</span>
<span class="c1"># spark is an existing SparkSession</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM table&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inter-operating-rdd-dataframes">
<h3><a class="toc-backref" href="#id11">2.4.2. Inter-operating RDD &amp; DataFrames</a><a class="headerlink" href="#inter-operating-rdd-dataframes" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal"><span class="pre">Rows</span></code> are constructed from a list of key/value pairs. The key will be
inferred as the column names of the table.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark is an existing SparkSession.</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># Load a text file and convert each line to a Row.</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.txt&quot;</span><span class="p">)</span>
<span class="n">parts</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
<span class="n">people</span> <span class="o">=</span> <span class="n">parts</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">age</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>

<span class="c1">#======================================================================#</span>
<span class="c1"># Here, create DF from Row object by inferring scheme</span>
<span class="c1"># (key values will be used as column names)</span>
<span class="c1">#======================================================================#</span>
<span class="c1"># Infer the schema, and register the DataFrame as a table.</span>
<span class="n">schemaPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">people</span><span class="p">)</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="c1"># SQL can be run over DataFrames that have been registered as a table.</span>
<span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>

<span class="c1"># The results of SQL queries are RDDs and support all the normal RDD operations.</span>
<span class="n">teenNames</span> <span class="o">=</span> <span class="n">teenagers</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">teenName</span> <span class="ow">in</span> <span class="n">teenNames</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">teenName</span><span class="p">)</span>

<span class="c1">#======================================================================#</span>
<span class="c1"># Programmatically Specifying the Schema</span>
<span class="c1">#======================================================================#</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># The schema is encoded in a string.</span>
<span class="n">schemaString</span> <span class="o">=</span> <span class="s2">&quot;name age&quot;</span>

<span class="n">fields</span> <span class="o">=</span> <span class="p">[</span><span class="n">StructField</span><span class="p">(</span><span class="n">field_name</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">field_name</span> <span class="ow">in</span> <span class="n">schemaString</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>

<span class="c1"># Apply the schema to the RDD.</span>
<span class="n">schemaPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">people</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>

<span class="c1"># Creates a temporary view using the DataFrame</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="c1"># SQL can be run over DataFrames that have been registered as a table.</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people&quot;</span><span class="p">)</span>

<span class="c1"># The results of SQL queries are RDDs and support all the normal RDD operations.</span>
<span class="n">names</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="data-sources">
<h3><a class="toc-backref" href="#id12">2.4.3. Data Sources</a><a class="headerlink" href="#data-sources" title="Permalink to this headline"></a></h3>
<p><strong>Registering</strong> a DataFrame as a <strong>temporary view</strong> allows you to run SQL queries over its data</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># simplest load/save (default datasource = parquet)</span>
<span class="c1"># (default can be configureated in spark.sql.sources.default)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndFavColors.parquet&quot;</span><span class="p">)</span>

<span class="c1"># or you can manually specify options</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndAges.parquet&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span>

<span class="c1"># can run sql queries on files directly</span>
<span class="c1"># (Instead of using read API to load a file into DataFrame and query it,</span>
<span class="c1">#  you can also query that file directly with SQL.)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="p">)</span>

<span class="c1"># for save modes, see:</span>
<span class="c1"># https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes</span>
</pre></div>
</div>
</div>
<div class="section" id="saving-to-persistent-tables">
<h3><a class="toc-backref" href="#id13">2.4.4. Saving to Persistent Tables</a><a class="headerlink" href="#saving-to-persistent-tables" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes">https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes</a></p>
<p>DataFrames can also be saved as persistent tables into Hive metastore using
the saveAsTable command. Notice existing Hive deployment is not necessary to
use this feature. Spark will create a default local Hive metastore (using
Derby) for you. Unlike the createOrReplaceTempView command, saveAsTable will
materialize the contents of the DataFrame and create a pointer to the data in
the Hive metastore. Persistent tables will still exist even after your Spark
program has restarted, as long as you maintain your connection to the same
metastore. A DataFrame for a persistent table can be created by calling the
table method on a SparkSession with the name of the table.</p>
<p>By default saveAsTable will create a managed table, meaning that the
location of the data will be controlled by the metastore. Managed tables will
also have their data deleted automatically when a table is dropped.</p>
<div class="section" id="parquet-files">
<h4>2.4.4.1. Parquet Files<a class="headerlink" href="#parquet-files" title="Permalink to this headline"></a></h4>
<p><a class="reference external" href="http://parquet.io/">Parquet</a> is a columnar format that is supported by many
other data processing systems.</p>
<ul class="simple">
<li>Spark SQL provides support for both reading and writing Parquet files that
automatically preserves the schema of the original data.</li>
<li>When writing Parquet files, all columns are automatically converted to be
nullable for compatibility reasons.</li>
<li>The loaded parquet files are DataFrames</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark from the previous example is used in this example.</span>

<span class="n">schemaPeople</span> <span class="c1"># The DataFrame from the previous example.</span>

<span class="c1"># DataFrames can be saved as Parquet files, maintaining the schema information.</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;people.parquet&quot;</span><span class="p">)</span>

<span class="c1"># Read in the Parquet file created above. Parquet files are self-describing so the schema is preserved.</span>
<span class="c1"># The result of loading a parquet file is also a DataFrame.</span>
<span class="n">parquetFile</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;people.parquet&quot;</span><span class="p">)</span>

<span class="c1"># Parquet files can also be used to create a temporary view and then used in SQL statements.</span>
<span class="n">parquetFile</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;parquetFile&quot;</span><span class="p">);</span>
<span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM parquetFile WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>
<span class="n">teenNames</span> <span class="o">=</span> <span class="n">teenagers</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">teenName</span> <span class="ow">in</span> <span class="n">teenNames</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">teenName</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="schema-merging">
<h4>2.4.4.2. Schema merging<a class="headerlink" href="#schema-merging" title="Permalink to this headline"></a></h4>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-programming-guide.html#schema-merging">https://spark.apache.org/docs/latest/sql-programming-guide.html#schema-merging</a></p>
<blockquote>
<div>Not a necessity in most cases.</div></blockquote>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark from the previous example is used in this example.</span>

<span class="c1"># Create a simple DataFrame, stored into a partition directory</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>\
                                   <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">single</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">double</span><span class="o">=</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">df1</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table/key=1&quot;</span><span class="p">)</span>

<span class="c1"># Create another DataFrame in a new partition directory,</span>
<span class="c1"># adding a new column and dropping an existing column</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
                                   <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">single</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">triple</span><span class="o">=</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">df2</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table/key=2&quot;</span><span class="p">)</span>

<span class="c1"># Read the partitioned table</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;mergeSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table&quot;</span><span class="p">)</span>
<span class="n">df3</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>

<span class="c1"># The final schema consists of all 3 columns in the Parquet files together</span>
<span class="c1"># with the partitioning column appeared in the partition directory paths.</span>
<span class="c1"># root</span>
<span class="c1"># |-- single: int (nullable = true)</span>
<span class="c1"># |-- double: int (nullable = true)</span>
<span class="c1"># |-- triple: int (nullable = true)</span>
<span class="c1"># |-- key : int (nullable = true)</span>
</pre></div>
</div>
</div>
<div class="section" id="json-datasets">
<h4>2.4.4.3. JSON Datasets<a class="headerlink" href="#json-datasets" title="Permalink to this headline"></a></h4>
<p>Spark SQL can automatically infer the schema of a JSON dataset and load it as a DataFrame</p>
<ul class="simple">
<li>Note that the file that is offered as a json file is not a typical JSON file.</li>
<li>Each line must contain a separate, self-contained valid JSON object.</li>
<li>As a consequence, a regular multi-line JSON file will most often fail.</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark is an existing SparkSession.</span>

<span class="c1"># A JSON dataset is pointed to by path.</span>
<span class="c1"># The path can be either a single text file or a directory storing text files.</span>
<span class="n">people</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">)</span>

<span class="c1"># The inferred schema can be visualized using the printSchema() method.</span>
<span class="n">people</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root</span>
<span class="c1">#  |-- age: long (nullable = true)</span>
<span class="c1">#  |-- name: string (nullable = true)</span>

<span class="c1"># Creates a temporary view using the DataFrame.</span>
<span class="n">people</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="c1"># SQL statements can be run by using the sql methods provided by `spark`.</span>
<span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>

<span class="c1"># Alternatively, a DataFrame can be created for a JSON dataset represented by</span>
<span class="c1"># an RDD[String] storing one JSON object per string.</span>
<span class="n">anotherPeopleRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
  <span class="s1">&#39;{&quot;name&quot;:&quot;Yin&quot;,&quot;address&quot;:{&quot;city&quot;:&quot;Columbus&quot;,&quot;state&quot;:&quot;Ohio&quot;}}&#39;</span><span class="p">])</span>
<span class="n">anotherPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">jsonRDD</span><span class="p">(</span><span class="n">anotherPeopleRDD</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="programming-guide-condensed-summary">
<h2><a class="toc-backref" href="#id14">2.5. Programming-guide: condensed summary</a><a class="headerlink" href="#programming-guide-condensed-summary" title="Permalink to this headline"></a></h2>
<p>From <a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">http://spark.apache.org/docs/latest/programming-guide.html</a></p>
<div class="section" id="super-basics">
<h3><a class="toc-backref" href="#id15">2.5.1. Super basics</a><a class="headerlink" href="#super-basics" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li>use the <code class="docutils literal"><span class="pre">bin/spark-submit</span></code> script in the Spark directory to run Spark applications in Python</li>
</ul>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>python3.4 bin/pyspark
$ <span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/opt/pypy-2.5/bin/pypy bin/spark-submit examples/src/main/python/pi.py
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span><span class="p">,</span> <span class="n">SparkConf</span>

<span class="c1">#=========================================================================#</span>
<span class="c1"># 1st thing a Spark program must do: create SC object that tells Spark how to access a cluster</span>
<span class="c1">#=========================================================================#</span>
<span class="c1"># create config object (contains information about your application)</span>
<span class="c1"># - `appName` = name of the application to show on the cluster UI</span>
<span class="c1"># - `master` = &quot;local&quot;, or URL to Spark, Mesos, or YARN cluster.</span>
<span class="c1">#   (http://spark.apache.org/docs/latest/submitting-applications.html#master-urls)</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="n">appName</span><span class="p">)</span><span class="o">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>

<span class="c1"># create SparkContext object</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>

<span class="c1"># === create RDD from an existing collection/iterable ===</span>
<span class="c1"># - use sc.parallelize</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">distData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># create Parallelized collections</span>
<span class="n">distData</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># partitions (typically 2-4 partitions for each CPU in cluster</span>
<span class="n">distData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">partitions</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># can also specify</span>
<span class="n">wordsRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="s2">&quot;fish&quot;</span><span class="p">,</span> <span class="s2">&quot;cats&quot;</span><span class="p">,</span> <span class="s2">&quot;dogs&quot;</span><span class="p">])</span>


<span class="c1"># === RDD external dataset ===</span>
<span class="c1"># - use sc.textFile</span>
<span class="c1"># URI = either a local path on the machine, or a hdfs://, s3n://, etc URI</span>
<span class="n">distFile</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data.txt&quot;</span><span class="p">)</span>
<span class="n">distFile</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># All of Sparks file-based input methods, including textFile,</span>
<span class="c1"># support running on directories, compressed files, and wildcards</span>
<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;/my/directory&quot;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;/my/directory/*.txt&quot;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;/my/directory/*.gz&quot;</span><span class="p">)</span>


<span class="c1">#==========================================================================#</span>
<span class="c1"># saving and loading</span>
<span class="c1">#==========================================================================#</span>
<span class="c1"># Similarly to text files, SequenceFiles can be saved and loaded by specifying the path</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span> <span class="o">*</span> <span class="n">x</span> <span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rdd</span><span class="o">.</span><span class="n">saveAsSequenceFile</span><span class="p">(</span><span class="s2">&quot;path/to/file&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">sequenceFile</span><span class="p">(</span><span class="s2">&quot;path/to/file&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>
<span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">u&#39;a&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">u&#39;aa&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">u&#39;aaa&#39;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="section" id="shared-variables">
<h3><a class="toc-backref" href="#id16">2.5.2. Shared variables</a><a class="headerlink" href="#shared-variables" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li>General, read-write shared variables across tasks would be inefficient.</li>
<li>However, Spark does provide two limited types of shared variables for two common usage patterns: broadcast variables and accumulators.</li>
</ul>
<div class="section" id="broadast-variables">
<h4>2.5.2.1. Broadast variables<a class="headerlink" href="#broadast-variables" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">SparkContext.broadcast(v)</span></code> - creates Broadcast variables from variable v.<ul>
<li>The broadcast variable is a wrapper around v, and its value can be accessed by
calling the <code class="docutils literal"><span class="pre">.value</span></code> method</li>
</ul>
</li>
<li>Broadcast variables are used to keep a read-only variable cached on each machine
(rather than shipping a copy of it with tasks).<ul>
<li>example usage: to give every node a copy of a large input dataset in an efficient manner.</li>
</ul>
</li>
<li>explicitly creating broadcast variables is only useful when tasks across multiple
stages need the same data or when caching the data in deserialized form is important.</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">broadcastVar</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">&lt;pyspark.broadcast.Broadcast object at 0x102789f10&gt;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span>
<span class="go">[1, 2, 3]</span>
</pre></div>
</div>
</div>
<div class="section" id="accumulators">
<h4>2.5.2.2. Accumulators<a class="headerlink" href="#accumulators" title="Permalink to this headline"></a></h4>
<p>See <a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html#accumulators">http://spark.apache.org/docs/latest/programming-guide.html#accumulators</a></p>
</div>
</div>
<div class="section" id="rdd-operations">
<h3><a class="toc-backref" href="#id17">2.5.3. RDD operations</a><a class="headerlink" href="#rdd-operations" title="Permalink to this headline"></a></h3>
<div class="section" id="rdd-basics">
<h4>2.5.3.1. RDD-basics<a class="headerlink" href="#rdd-basics" title="Permalink to this headline"></a></h4>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data.txt&quot;</span><span class="p">)</span>
<span class="n">lineLengths</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
<span class="n">totalLength</span> <span class="o">=</span> <span class="n">lineLengths</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">lineLengths</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span> <span class="c1"># if you want to use this object again later</span>
</pre></div>
</div>
</div>
<div class="section" id="passing-functions-to-spark">
<h4>2.5.3.2. Passing functions to Spark<a class="headerlink" href="#passing-functions-to-spark" title="Permalink to this headline"></a></h4>
<p>Spark relies heavily on passing functions in the driver program to run on the cluster.</p>
<p>3 recommended ways to do this:</p>
<p>1. lambda expressions for simple functions (does not support mult-statement functions or statements that do not return a value)
2. Local <code class="docutils literal"><span class="pre">def</span></code> functions
3. Top-level functions in a module</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">myFunc</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;file.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">myFunc</span><span class="p">)</span>
</pre></div>
</div>
<p>Some caveats when defining class attributes</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># don&#39;t do this (the whole object gets sent to the luster when ``doStuff`` is called)</span>
<span class="k">class</span> <span class="nc">MyClass</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">s</span>
    <span class="k">def</span> <span class="nf">doStuff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>

<span class="c1"># or this (accessing fields of the outer object will reference the ENTIRE object)</span>
<span class="k">class</span> <span class="nc">MyClass</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="s2">&quot;Hello&quot;</span>
    <span class="k">def</span> <span class="nf">doStuff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span>

<span class="c1"># rather, do this (copy field into a local variable instead of accessing it externally)</span>
<span class="k">def</span> <span class="nf">doStuff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
    <span class="n">field</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span>
    <span class="k">return</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">field</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rdd-transformations">
<h4>2.5.3.3. RDD Transformations<a class="headerlink" href="#rdd-transformations" title="Permalink to this headline"></a></h4>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html#transformations">http://spark.apache.org/docs/latest/programming-guide.html#transformations</a></p>
</div>
<div class="section" id="rdd-actions">
<h4>2.5.3.4. RDD Actions<a class="headerlink" href="#rdd-actions" title="Permalink to this headline"></a></h4>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html#actions">http://spark.apache.org/docs/latest/programming-guide.html#actions</a></p>
</div>
<div class="section" id="closures">
<h4>2.5.3.5. closures<a class="headerlink" href="#closures" title="Permalink to this headline"></a></h4>
<p>Common confusion in Spark:</p>
<ul class="simple">
<li>understanding the <strong>scope</strong> and <strong>life cycle</strong> of variables and methods when
executing code across a cluster.</li>
<li>In general, <strong>closures</strong> - constructs like loops or locally defined methods,
should not be used to mutate some global state.</li>
<li>Use an <strong>Accumulator</strong> instead if some global aggregation is needed.</li>
</ul>
<p>Example: wrong way to increment a counter</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Wrong: Don&#39;t do this!! (will only work in master=&quot;local&quot; mode, but won&#39;t work on cluster)</span>
<span class="k">def</span> <span class="nf">increment_counter</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">counter</span>
    <span class="n">counter</span> <span class="o">+=</span> <span class="n">x</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">increment_counter</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Counter value: &quot;</span><span class="p">,</span> <span class="n">counter</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="working-with-key-value-pairs">
<h4>2.5.3.6. Working with key-value pairs<a class="headerlink" href="#working-with-key-value-pairs" title="Permalink to this headline"></a></h4>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data.txt&quot;</span><span class="p">)</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">pairs</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="o">.</span><span class="n">sortByKey</span><span class="p">()</span> <span class="c1"># sort alphabetically</span>
<span class="n">counts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="c1"># bring them back to the driver program as a list of objects</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="random-handy-snippets">
<h2><a class="toc-backref" href="#id18">2.6. Random handy snippets</a><a class="headerlink" href="#random-handy-snippets" title="Permalink to this headline"></a></h2>
<div class="section" id="compute-average">
<h3><a class="toc-backref" href="#id19">2.6.1. compute average</a><a class="headerlink" href="#compute-average" title="Permalink to this headline"></a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># using RDDs</span>
<span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">x</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">x</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">toFloat</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="p">}</span><span class="o">.</span>
<span class="n">reduceByKey</span> <span class="p">{</span> <span class="n">case</span> <span class="p">((</span><span class="n">num1</span><span class="p">,</span> <span class="n">count1</span><span class="p">),</span> <span class="p">(</span><span class="n">num2</span><span class="p">,</span> <span class="n">count2</span><span class="p">))</span> <span class="o">=&gt;</span>
<span class="p">(</span><span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span><span class="p">,</span> <span class="n">count1</span> <span class="o">+</span> <span class="n">count2</span><span class="p">)</span>
<span class="p">}</span><span class="o">.</span>
<span class="nb">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">count</span><span class="p">))</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">num</span> <span class="o">/</span> <span class="n">count</span><span class="p">)</span> <span class="p">}</span><span class="o">.</span>
<span class="n">collect</span><span class="p">()</span>

<span class="c1"># using DF</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.functions._</span>
<span class="n">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">a</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">a</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">a</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">avg</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">))</span>
<span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="cs-py-jupyter-notebook.html" class="btn btn-neutral float-right" title="3. python-jupyter-notebook" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="cs-python.html" class="btn btn-neutral" title="1. Python" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Takanori Watanabe.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>